{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 2: Waymo Open Dataset 다운로드 함수\n",
    "def download_waymo_dataset():\n",
    "    \"\"\"\n",
    "    Waymo Open Dataset을 다운로드하고 접근합니다.\n",
    "    라이선스 등록이 완료된 상태여야 합니다.\n",
    "    \"\"\"\n",
    "    print(\"Waymo Open Dataset을 다운로드하는 중...\")\n",
    "    \n",
    "    try:\n",
    "        # Waymo Open Dataset v1.2 (기본 구성) 접근\n",
    "        dataset = tfds.load(\n",
    "            'waymo_open_dataset/v1.2'\n",
    "            # 다른 경로가 필요하면 아래 주석을 해제하고 경로를 수정하세요\n",
    "            # data_dir='gs://waymo_open_dataset_v_1_2_0_individual_files/tensorflow_datasets'\n",
    "        )\n",
    "        \n",
    "        print(\"데이터셋 로드 성공!\")\n",
    "        return dataset\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"데이터셋 로드 중 오류 발생: {e}\")\n",
    "        \n",
    "        # 대체 방법: v1.0 버전으로 시도\n",
    "        try:\n",
    "            print(\"v1.0 버전으로 다시 시도합니다...\")\n",
    "            dataset = tfds.load(\n",
    "                'waymo_open_dataset/v1.0',\n",
    "                data_dir='gs://waymo_open_dataset_v_1_0_0_individual_files/tensorflow_datasets'\n",
    "            )\n",
    "            print(\"v1.0 데이터셋 로드 성공!\")\n",
    "            return dataset\n",
    "        except Exception as e2:\n",
    "            print(f\"v1.0 데이터셋 로드 중 오류 발생: {e2}\")\n",
    "            print(\"라이선스 등록 상태를 다시 확인하거나 GCS 접근 권한을 확인하세요.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 3: 데이터셋 탐색 함수\n",
    "def explore_dataset(dataset):\n",
    "    \"\"\"\n",
    "    데이터셋 구조를 탐색합니다.\n",
    "    \"\"\"\n",
    "    if dataset is None:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n데이터셋 구조 탐색:\")\n",
    "    print(\"사용 가능한 분할:\", dataset.keys())\n",
    "    \n",
    "    # 훈련 데이터셋의 첫 번째 샘플 확인\n",
    "    train_dataset = dataset['train']\n",
    "    \n",
    "    for example in train_dataset.take(1):\n",
    "        print(\"\\n데이터셋 키:\", list(example.keys()))\n",
    "        \n",
    "        # 카메라 이미지 정보 확인\n",
    "        for camera in ['camera_FRONT', 'camera_FRONT_LEFT', 'camera_FRONT_RIGHT', \n",
    "                       'camera_SIDE_LEFT', 'camera_SIDE_RIGHT']:\n",
    "            if camera in example:\n",
    "                print(f\"\\n{camera} 이미지 형태:\", example[camera]['image'].shape)\n",
    "                labels = example[camera]['labels']\n",
    "                if 'type' in labels:\n",
    "                    print(f\"{camera} 레이블 개수:\", len(labels['type']))\n",
    "                    # 레이블이 있는 경우 레이블 값 확인\n",
    "                    if len(labels['type']) > 0:\n",
    "                        print(f\"{camera} 첫 번째 레이블 타입:\", labels['type'][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 4: 샘플 이미지 시각화 함수\n",
    "def visualize_sample(dataset):\n",
    "    \"\"\"\n",
    "    데이터셋의 샘플 이미지를 시각화합니다.\n",
    "    \"\"\"\n",
    "    if dataset is None:\n",
    "        return\n",
    "    \n",
    "    train_dataset = dataset['train']\n",
    "    \n",
    "    for example in train_dataset.take(1):\n",
    "        # 전방 카메라 이미지 시각화\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        cameras = ['camera_FRONT', 'camera_FRONT_LEFT', 'camera_FRONT_RIGHT', \n",
    "                   'camera_SIDE_LEFT', 'camera_SIDE_RIGHT']\n",
    "        \n",
    "        for i, camera in enumerate(cameras):\n",
    "            if camera in example:\n",
    "                plt.subplot(2, 3, i+1)\n",
    "                plt.imshow(example[camera]['image'])\n",
    "                plt.title(camera)\n",
    "                \n",
    "                # 바운딩 박스 추가\n",
    "                if len(example[camera]['labels']['bbox']) > 0:\n",
    "                    for bbox in example[camera]['labels']['bbox']:\n",
    "                        y1, x1, y2, x2 = bbox.numpy()\n",
    "                        height, width = example[camera]['image'].shape[0:2]\n",
    "                        \n",
    "                        # 정규화된 좌표를 실제 픽셀 좌표로 변환\n",
    "                        x1 = int(x1 * width)\n",
    "                        y1 = int(y1 * height)\n",
    "                        x2 = int(x2 * width)\n",
    "                        y2 = int(y2 * height)\n",
    "                        \n",
    "                        # 바운딩 박스 그리기\n",
    "                        plt.gca().add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                                         fill=False, edgecolor='red', linewidth=2))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 5: 3D CNN 모델을 위한 데이터 전처리 함수\n",
    "# 3D CNN 모델의 입력 형태 정의\n",
    "INPUT_DEPTH = 16    # 시간축 길이 (연속된 프레임 수)\n",
    "INPUT_HEIGHT = 32   # 이미지 높이\n",
    "INPUT_WIDTH = 32    # 이미지 너비\n",
    "NUM_CLASSES = 5     # Waymo 데이터셋의 클래스 수\n",
    "\n",
    "def preprocess_waymo_data(dataset, max_samples=1000, save_dir='processed_data'):\n",
    "    \"\"\"\n",
    "    Waymo 데이터셋을 3D CNN 모델에 맞게 전처리합니다.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Waymo 데이터셋\n",
    "        max_samples: 처리할 최대 샘플 수\n",
    "        save_dir: 처리된 데이터를 저장할 디렉토리\n",
    "    \n",
    "    Returns:\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 데이터 저장 경로\n",
    "    X_path = os.path.join(save_dir, 'X_data.npy')\n",
    "    y_path = os.path.join(save_dir, 'y_data.npy')\n",
    "    \n",
    "    # 이미 처리된 데이터가 있는지 확인\n",
    "    if os.path.exists(X_path) and os.path.exists(y_path):\n",
    "        print(\"로드된 전처리 데이터를 사용합니다.\")\n",
    "        X_data = np.load(X_path)\n",
    "        y_data = np.load(y_path)\n",
    "    else:\n",
    "        print(\"데이터 전처리를 시작합니다...\")\n",
    "        X_data = []\n",
    "        y_data = []\n",
    "        \n",
    "        train_dataset = dataset['train']\n",
    "        count = 0\n",
    "        \n",
    "        for example in tqdm(train_dataset):\n",
    "            if count >= max_samples:\n",
    "                break\n",
    "                \n",
    "            # 전방 카메라 이미지와 레이블 사용\n",
    "            front_camera = example['camera_FRONT']\n",
    "            images = front_camera['image']\n",
    "            labels = front_camera['labels']['type']\n",
    "            \n",
    "            # 레이블이 있는 경우만 처리\n",
    "            if len(labels) > 0:\n",
    "                # 첫 번째 객체 레이블 사용 (단순화를 위해)\n",
    "                label = labels[0].numpy()\n",
    "                \n",
    "                # 이미지 전처리\n",
    "                img = images.numpy()\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "                img_resized = cv2.resize(img_gray, (INPUT_WIDTH, INPUT_HEIGHT))\n",
    "                \n",
    "                # 샘플 추가\n",
    "                X_data.append(img_resized)\n",
    "                y_data.append(label)\n",
    "                \n",
    "                count += 1\n",
    "        \n",
    "        # 3D 데이터 생성 (가상의 시간 차원 생성)\n",
    "        # 실제 시나리오에서는 연속된 프레임을 사용해야 합니다\n",
    "        print(\"3D 데이터 생성 중...\")\n",
    "        X_3d = []\n",
    "        \n",
    "        # 충분한 샘플이 있는지 확인\n",
    "        if len(X_data) >= INPUT_DEPTH:\n",
    "            for i in range(len(X_data) - INPUT_DEPTH + 1):\n",
    "                # INPUT_DEPTH 개수의 연속된 프레임을 하나의 3D 샘플로 구성\n",
    "                sequence = np.array(X_data[i:i+INPUT_DEPTH])\n",
    "                sequence = sequence.reshape(INPUT_DEPTH, INPUT_HEIGHT, INPUT_WIDTH, 1)\n",
    "                X_3d.append(sequence)\n",
    "            \n",
    "            # 레이블 조정 (첫 번째 프레임의 레이블을 시퀀스 레이블로 사용)\n",
    "            y_3d = y_data[:len(X_3d)]\n",
    "            \n",
    "            # numpy 배열로 변환\n",
    "            X_data = np.array(X_3d)\n",
    "            y_data = np.array(y_3d)\n",
    "            \n",
    "            # 저장\n",
    "            np.save(X_path, X_data)\n",
    "            np.save(y_path, y_data)\n",
    "        else:\n",
    "            print(f\"경고: 샘플이 충분하지 않습니다. 필요: {INPUT_DEPTH}, 실제: {len(X_data)}\")\n",
    "            return None, None, None, None, None, None\n",
    "    \n",
    "    # 데이터 정보 출력\n",
    "    print(f\"데이터 형태: {X_data.shape}\")\n",
    "    print(f\"레이블 형태: {y_data.shape}\")\n",
    "    print(f\"고유 클래스: {np.unique(y_data)}\")\n",
    "    \n",
    "    # 데이터 분할 (훈련/검증/테스트)\n",
    "    # 먼저 훈련+검증 데이터와 테스트 데이터 분할\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X_data, y_data, test_size=0.2, random_state=42, stratify=y_data\n",
    "    )\n",
    "    \n",
    "    # 훈련 데이터와 검증 데이터 분할\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # 레이블을 one-hot 인코딩으로 변환\n",
    "    y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "    y_val = to_categorical(y_val, NUM_CLASSES)\n",
    "    y_test = to_categorical(y_test, NUM_CLASSES)\n",
    "    \n",
    "    print(f\"훈련 데이터: {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"검증 데이터: {X_val.shape}, {y_val.shape}\")\n",
    "    print(f\"테스트 데이터: {X_test.shape}, {y_test.shape}\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 6: 시간적 정보가 있는 경우의 대체 전처리 방법\n",
    "def preprocess_temporal_data(dataset, max_samples=1000, temporal_window=16, save_dir='processed_temporal_data'):\n",
    "    \"\"\"\n",
    "    시간적 정보가 있는 경우 Waymo 데이터셋을 3D CNN 모델에 맞게 전처리합니다.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Waymo 데이터셋\n",
    "        max_samples: 처리할 최대 샘플 수\n",
    "        temporal_window: 시간 창 크기\n",
    "        save_dir: 처리된 데이터를 저장할 디렉토리\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    X_path = os.path.join(save_dir, 'X_temporal_data.npy')\n",
    "    y_path = os.path.join(save_dir, 'y_temporal_data.npy')\n",
    "    \n",
    "    if os.path.exists(X_path) and os.path.exists(y_path):\n",
    "        print(\"로드된 시간적 데이터를 사용합니다.\")\n",
    "        X_data = np.load(X_path)\n",
    "        y_data = np.load(y_path)\n",
    "        return X_data, y_data\n",
    "    \n",
    "    # 시간순으로 정렬된 프레임 저장을 위한 사전\n",
    "    temporal_frames = {}\n",
    "    \n",
    "    train_dataset = dataset['train']\n",
    "    count = 0\n",
    "    \n",
    "    print(\"시간 정보를 사용하여 데이터 수집 중...\")\n",
    "    for example in tqdm(train_dataset):\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "            \n",
    "        # 타임스탬프 추출\n",
    "        timestamp = example['timestamp_micros'].numpy()\n",
    "        context_name = example['context']['name'].numpy().decode('utf-8')\n",
    "        \n",
    "        # 컨텍스트별로 프레임 그룹화\n",
    "        if context_name not in temporal_frames:\n",
    "            temporal_frames[context_name] = []\n",
    "        \n",
    "        # 전방 카메라 이미지와 레이블 사용\n",
    "        front_camera = example['camera_FRONT']\n",
    "        image = front_camera['image'].numpy()\n",
    "        \n",
    "        # 레이블이 있는 경우만 처리\n",
    "        if len(front_camera['labels']['type']) > 0:\n",
    "            label = front_camera['labels']['type'][0].numpy()\n",
    "            \n",
    "            # 이미지 전처리\n",
    "            img_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            img_resized = cv2.resize(img_gray, (INPUT_WIDTH, INPUT_HEIGHT))\n",
    "            \n",
    "            # 프레임 정보 저장\n",
    "            temporal_frames[context_name].append({\n",
    "                'timestamp': timestamp,\n",
    "                'image': img_resized,\n",
    "                'label': label\n",
    "            })\n",
    "            \n",
    "            count += 1\n",
    "    \n",
    "    print(f\"수집된 컨텍스트 수: {len(temporal_frames)}\")\n",
    "    \n",
    "    # 3D 데이터 생성\n",
    "    X_3d = []\n",
    "    y_3d = []\n",
    "    \n",
    "    for context, frames in temporal_frames.items():\n",
    "        # 타임스탬프로 정렬\n",
    "        frames.sort(key=lambda x: x['timestamp'])\n",
    "        \n",
    "        # 충분한 프레임이 있는 경우만 처리\n",
    "        if len(frames) >= temporal_window:\n",
    "            for i in range(len(frames) - temporal_window + 1):\n",
    "                # temporal_window 크기의 연속된 프레임을 하나의 3D 샘플로 구성\n",
    "                sequence = np.array([frame['image'] for frame in frames[i:i+temporal_window]])\n",
    "                sequence = sequence.reshape(temporal_window, INPUT_HEIGHT, INPUT_WIDTH, 1)\n",
    "                \n",
    "                # 시퀀스의 마지막 프레임 레이블 사용\n",
    "                label = frames[i+temporal_window-1]['label']\n",
    "                \n",
    "                X_3d.append(sequence)\n",
    "                y_3d.append(label)\n",
    "    \n",
    "    # numpy 배열로 변환\n",
    "    if X_3d:\n",
    "        X_data = np.array(X_3d)\n",
    "        y_data = np.array(y_3d)\n",
    "        \n",
    "        # 저장\n",
    "        np.save(X_path, X_data)\n",
    "        np.save(y_path, y_data)\n",
    "        \n",
    "        print(f\"시간적 데이터 형태: {X_data.shape}\")\n",
    "        print(f\"시간적 레이블 형태: {y_data.shape}\")\n",
    "        \n",
    "        return X_data, y_data\n",
    "    else:\n",
    "        print(\"충분한 시간적 데이터를 생성할 수 없습니다.\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 7: 메인 실행 함수\n",
    "def main():\n",
    "    # Waymo 데이터셋 가져오기\n",
    "    dataset = download_waymo_dataset()\n",
    "    \n",
    "    if dataset is None:\n",
    "        print(\"데이터셋을 불러올 수 없습니다.\")\n",
    "        return\n",
    "        \n",
    "    # 데이터셋 구조 탐색\n",
    "    explore_dataset(dataset)\n",
    "    \n",
    "    # 샘플 시각화\n",
    "    visualize_sample(dataset)\n",
    "    \n",
    "    # 기본 전처리 방법\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = preprocess_waymo_data(\n",
    "        dataset, max_samples=1000\n",
    "    )\n",
    "    \n",
    "    # X_train이 None이면 데이터 처리에 실패한 것\n",
    "    if X_train is None:\n",
    "        print(\"데이터 전처리 실패. 프로그램을 종료합니다.\")\n",
    "        return\n",
    "    \n",
    "    # 시간적 정보를 활용한 전처리 방법 (선택 사항)\n",
    "    # X_temporal, y_temporal = preprocess_temporal_data(dataset)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout3DCNN(tf.keras.Model):\n",
    "    def __init__(self, input_shape, num_classes=5, dropout_rate=0.3):\n",
    "        super(MCDropout3DCNN, self).__init__()\n",
    "        \n",
    "        # 첫 번째 3D 합성곱 블록\n",
    "        self.conv1_1 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')\n",
    "        self.bn1_1 = layers.BatchNormalization()\n",
    "        self.conv1_2 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')\n",
    "        self.bn1_2 = layers.BatchNormalization()\n",
    "        self.pool1 = layers.MaxPool3D(pool_size=2)\n",
    "        self.drop1 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        # 두 번째 3D 합성곱 블록\n",
    "        self.conv2_1 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.bn2_1 = layers.BatchNormalization()\n",
    "        self.conv2_2 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.bn2_2 = layers.BatchNormalization()\n",
    "        self.pool2 = layers.MaxPool3D(pool_size=2)\n",
    "        self.drop2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        # 세 번째 3D 합성곱 블록\n",
    "        self.conv3_1 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same',\n",
    "                           kernel_regularizer=regularizers.l2(1e-4))\n",
    "        self.bn3_1 = layers.BatchNormalization()\n",
    "        self.conv3_2 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same',\n",
    "                           kernel_regularizer=regularizers.l2(1e-4))\n",
    "        self.bn3_2 = layers.BatchNormalization()\n",
    "        self.pool3 = layers.MaxPool3D(pool_size=2)\n",
    "        self.drop3 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        # 완전 연결 계층\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense1 = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.drop4 = layers.Dropout(dropout_rate)\n",
    "        self.dense2 = layers.Dense(num_classes, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        # 첫 번째 블록\n",
    "        x = self.conv1_1(inputs)\n",
    "        x = self.bn1_1(x, training=training)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.bn1_2(x, training=training)\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x, training=training)\n",
    "        \n",
    "        # 두 번째 블록\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.bn2_1(x, training=training)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.bn2_2(x, training=training)\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop2(x, training=training)\n",
    "        \n",
    "        # 세 번째 블록\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.bn3_1(x, training=training)\n",
    "        x = self.conv3_2(x)\n",
    "        x = self.bn3_2(x, training=training)\n",
    "        x = self.pool3(x)\n",
    "        x = self.drop3(x, training=training)\n",
    "        \n",
    "        # 완전 연결 계층\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn4(x, training=training)\n",
    "        x = self.drop4(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build_graph(self):\n",
    "        x = tf.keras.Input(shape=(16, 32, 32, 1))\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (16, 32, 32, 1)  # (depth, height, width, channels)\n",
    "mc_dropout_model = MCDropout3DCNN(input_shape)\n",
    "mc_dropout_graph = mc_dropout_model.build_graph()\n",
    "print(\"MC Dropout 모델 요약:\")\n",
    "mc_dropout_graph.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_dropout_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict(model, X, num_samples=30):\n",
    "    predictions = []\n",
    "    \n",
    "    # 학습 모드로 설정하여 드롭아웃 활성화\n",
    "    for _ in range(num_samples):\n",
    "        y_pred = model(X, training=True)\n",
    "        predictions.append(y_pred.numpy())\n",
    "    \n",
    "    # 예측값의 평균과 표준편차\n",
    "    mean_prediction = np.mean(predictions, axis=0)\n",
    "    std_prediction = np.std(predictions, axis=0)\n",
    "    \n",
    "    return mean_prediction, std_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uncertainty(mean_pred, std_pred, sample_idx=0):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # 각 클래스별 예측 확률과 불확실성\n",
    "    plt.subplot(1, 2, 1)\n",
    "    num_classes = mean_pred.shape[1]\n",
    "    classes = range(num_classes)\n",
    "    \n",
    "    plt.bar(classes, mean_pred[sample_idx], yerr=std_pred[sample_idx], capsize=10)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Prediction Probability with Uncertainty')\n",
    "    plt.xticks(classes)\n",
    "    \n",
    "    # 불확실성 분포\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(np.mean(std_pred, axis=1), bins=30)\n",
    "    plt.axvline(std_pred[sample_idx].mean(), color='r', linestyle='--', \n",
    "                label=f'Sample #{sample_idx} uncertainty')\n",
    "    plt.xlabel('Mean Uncertainty (Std)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Uncertainty Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uncertainty_vs_accuracy(mean_pred, std_pred, y_true):\n",
    "    # 예측 클래스와 실제 클래스\n",
    "    pred_classes = np.argmax(mean_pred, axis=1)\n",
    "    true_classes = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    # 정확한 예측과 잘못된 예측 구분\n",
    "    correct = pred_classes == true_classes\n",
    "    \n",
    "    # 각 샘플의 평균 불확실성\n",
    "    mean_uncertainty = np.mean(std_pred, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(mean_uncertainty[correct], np.ones(np.sum(correct)), \n",
    "                label='Correct Predictions', alpha=0.5, color='blue')\n",
    "    plt.scatter(mean_uncertainty[~correct], np.zeros(np.sum(~correct)), \n",
    "                label='Wrong Predictions', alpha=0.5, color='red')\n",
    "    \n",
    "    plt.xlabel('Mean Uncertainty (Std)')\n",
    "    plt.ylabel('Prediction Correctness')\n",
    "    plt.yticks([0, 1], ['Wrong', 'Correct'])\n",
    "    plt.title('Relationship Between Uncertainty and Prediction Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=16):\n",
    "    # 콜백 정의\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_dropout_model.save('mc_dropout_3dcnn_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # 정확도 시각화\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 손실 시각화\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_uncertainty(model, X_test, y_test):\n",
    "    # MC Dropout을 사용한 베이지안 추론\n",
    "    mean_pred, std_pred = mc_dropout_predict(model, X_test)\n",
    "    pred_classes = np.argmax(mean_pred, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = accuracy_score(true_classes, pred_classes)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # 혼동 행렬\n",
    "    conf_matrix = confusion_matrix(true_classes, pred_classes)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 분류 보고서\n",
    "    report = classification_report(true_classes, pred_classes)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # 불확실성 시각화\n",
    "    plot_uncertainty(mean_pred, std_pred)\n",
    "    \n",
    "    # 불확실성과 정확도 관계 분석\n",
    "    plot_uncertainty_vs_accuracy(mean_pred, std_pred, y_test)\n",
    "    \n",
    "    return mean_pred, std_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('mc_dropout_3dcnn_model')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
