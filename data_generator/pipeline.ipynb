{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_resnet.py\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 설정 ---\n",
    "TRAIN_DIR = '/home/work/AIprogramming/Ai_proj/data_generator/train_data'\n",
    "TEST_DIR  = '/home/work/AIprogramming/Ai_proj/data_generator/test_data'\n",
    "CHECKPOINT_DIR = './checkpoints'\n",
    "HISTORY_CSV    = './history.csv'\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS     = 30\n",
    "LR         = 1e-3\n",
    "DEVICE     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "def load_pt_folder(pt_dir):\n",
    "    \"\"\"폴더의 .pt 파일 전부 읽어서 하나의 TensorDataset으로 반환\"\"\"\n",
    "    imgs_list, labels_list = [], []\n",
    "    for path in sorted(glob.glob(os.path.join(pt_dir, '*.pt'))):\n",
    "        print(f'Loading {path} ...')\n",
    "        imgs, lbls = torch.load(path)\n",
    "        imgs_list.append(imgs)\n",
    "        labels_list.append(lbls)\n",
    "    imgs = torch.cat(imgs_list, dim=0)\n",
    "    lbls = torch.cat(labels_list, dim=0)\n",
    "    return TensorDataset(imgs, lbls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/train_data/clean.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/train_data/fgsm.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/train_data/mifgsm.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/train_data/pgd.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/train_data/rfgsm.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/test_data/clean.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/test_data/cw.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/test_data/fgsm.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/test_data/mifgsm.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/test_data/pgd.pt ...\n",
      "Loading /home/work/AIprogramming/Ai_proj/data_generator/test_data/rfgsm.pt ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:207: UserWarning: The parameter 'pretrained' is deprecated, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:220: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 1) 데이터 준비\n",
    "train_ds = load_pt_folder(TRAIN_DIR)\n",
    "test_ds  = load_pt_folder(TEST_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 2) 모델 준비 (ResNet-18, CIFAR10용으로 마지막 레이어 수정)\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# 3) 손실/최적화 준비\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5)\n",
    "\n",
    "# 4) 학습 루프\n",
    "history = []\n",
    "best_acc = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/30 | Train: loss=1.0335, acc=0.6343 | Val:   loss=0.9926, acc=0.6617 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/30 | Train: loss=0.5818, acc=0.7975 | Val:   loss=0.9916, acc=0.6913 *\n",
      "Epoch 03/30 | Train: loss=0.3383, acc=0.8820 | Val:   loss=1.2626, acc=0.6806 \n",
      "Epoch 04/30 | Train: loss=0.2042, acc=0.9287 | Val:   loss=1.2716, acc=0.6960 *\n",
      "Epoch 05/30 | Train: loss=0.1401, acc=0.9511 | Val:   loss=1.5534, acc=0.6791 \n",
      "Epoch 06/30 | Train: loss=0.1073, acc=0.9628 | Val:   loss=1.5710, acc=0.6863 \n",
      "Epoch 07/30 | Train: loss=0.0879, acc=0.9697 | Val:   loss=1.6469, acc=0.6898 \n",
      "Epoch 08/30 | Train: loss=0.0729, acc=0.9745 | Val:   loss=1.6257, acc=0.6993 *\n",
      "Epoch 09/30 | Train: loss=0.0626, acc=0.9784 | Val:   loss=1.6835, acc=0.7017 *\n",
      "Epoch 10/30 | Train: loss=0.0559, acc=0.9808 | Val:   loss=1.8116, acc=0.6987 \n",
      "Epoch 11/30 | Train: loss=0.0535, acc=0.9817 | Val:   loss=1.6705, acc=0.7011 \n",
      "Epoch 12/30 | Train: loss=0.0445, acc=0.9848 | Val:   loss=1.8421, acc=0.6986 \n",
      "Epoch 13/30 | Train: loss=0.0445, acc=0.9848 | Val:   loss=1.8191, acc=0.7026 *\n",
      "Epoch 14/30 | Train: loss=0.0397, acc=0.9863 | Val:   loss=1.9149, acc=0.6917 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        running_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc  = running_correct / len(train_loader.dataset)\n",
    "\n",
    "    # --- validate ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    val_loss /= len(test_loader.dataset)\n",
    "    val_acc  = val_correct / len(test_loader.dataset)\n",
    "\n",
    "    # --- 스케줄러 스텝 & 체크포인트 ---\n",
    "    scheduler.step(val_acc)\n",
    "    is_best = val_acc > best_acc\n",
    "    if is_best:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, 'best_resnet18.pth'))\n",
    "\n",
    "    # --- 히스토리 기록 ---\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} | \"\n",
    "          f\"Train: loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
    "          f\"Val:   loss={val_loss:.4f}, acc={val_acc:.4f} {'*' if is_best else ''}\")\n",
    "    history.append({\n",
    "        'epoch': epoch,\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 히스토리 저장\n",
    "pd.DataFrame(history).to_csv(HISTORY_CSV, index=False)\n",
    "print(\"Training complete. Best val_acc:\", best_acc)\n",
    "print(\"Checkpoint and history saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# (1) 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# (2) history.csv 읽기\n",
    "history = pd.read_csv('history.csv')\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# (3) Figure & Subplots 생성\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 3-1) 손실(Loss) 곡선\n",
    "axes[0].plot(history['epoch'], history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['epoch'], history['val_loss'],   label='Val   Loss', marker='s')\n",
    "axes[0].set_title('Loss vs. Epoch')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 3-2) 정확도(Accuracy) 곡선\n",
    "axes[1].plot(history['epoch'], history['train_acc'], label='Train Acc', marker='o')\n",
    "axes[1].plot(history['epoch'], history['val_acc'],   label='Val   Acc', marker='s')\n",
    "axes[1].set_title('Accuracy vs. Epoch')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
